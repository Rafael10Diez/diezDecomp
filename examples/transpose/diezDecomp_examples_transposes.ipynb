{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpose Examples\n",
    "This Jupyter notebook presents three examples performing transposes in diezDecomp:\n",
    "\n",
    "1) A simple `x-y` transpose with a grid layout (for the MPI tasks) going from $(p_x \\times p_y \\times p_z)=(1\\times2\\times4)$ to $(2\\times1\\times 4)$ (in the $x~y~z$ directions).\n",
    "     * This is a basic use-case for DNS/LES simulations.\n",
    "2) Advanced example with randomized grid layout for 8 GPUs/GCDs. The following challenges are addressed:\n",
    "     * Random transpose direction (`x/y/z`)\n",
    "     * Mismatched intersections between the 2D pencil decompositions.\n",
    "     * Custom array padding for each MPI task.\n",
    "     * Array order (e.g., `x-y-z` or `y-z-x`) is different for the input/output arrays.\n",
    "3)  Optional example, performing the same non-trivial transposes from Example 2, but using an advanced subroutine which does not require an additional memory buffer (`work`).\n",
    "     * The restrictions for using this subroutine are explained in detail below (Example 3).\n",
    "     * While not all applications can operate without a memory buffer (`work`), Poisson solvers and parallel tridiagonal solvers can often meet the required conditions, without interfering with the rest of the DNS/LES solver.\n",
    "\n",
    "The generic API is considered for all transpose examples (`diezdecomp_api_generic.f90`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Simple X-Y Transpose\n",
    "This example corresponds to one of the most simple use-cases encountered in DNS/LES solvers:\n",
    "* Performing a X-Y transpose between well-aligned 2-D pencil distributions.\n",
    "\n",
    "Globally, the grid size is:\n",
    "* $(N_x \\times N_y \\times N_z)=(200 \\times 320 \\times 440)$\n",
    "\n",
    "The original (x-aligned) grid layout for the MPI tasks is:\n",
    "* $(p_x \\times p_y \\times p_z)=(1 \\times 2 \\times 4)$\n",
    "\n",
    "After the transpose, the MPI grid layout is (y-aligned):\n",
    "* $(p_x \\times p_y \\times p_z)=(2 \\times 1 \\times 4)$\n",
    "\n",
    "The local grid size of each MPI task is:\n",
    "* $size(p_{in})=200 \\times 160 \\times 110$\n",
    "* $size(p_{out})=100 \\times 320 \\times 110$\n",
    "\n",
    "Please note that $p_z$ is constant for both cases, and thus there is no data transfer along the $z$-direction.\n",
    "\n",
    "Typically, DNS codes perform $x$-$y$ transposes inside Poisson solvers. First, a local 1D FFT operation is applied in the $x$-direction, then a $x$-$y$ transpose is called, and then a FFT is performed in the $y$-direction. Since 1D FFTs work faster when the entire 1D array is local to each GPU, it is common for DNS solvers to require that $x$-$y$ transposes use $p_x=1$ for the input array (`p_in`), and $p_y=1$ in the output array (`p_out`). This ensures that information is re-distributed, such that each GPU thread can read all the required data for the 1D FFT operations in the $x$ and $y$ directions.\n",
    "\n",
    "The correctness of the $x$-$y$ transpose is verified by pre-computing the expected values for each element in the arrays `p_in` and `p_out_ref` inside the code. (The array `p_out_ref` is never part of the transpose operation). Finally, the transpose operation is validated by checking the maximum difference between `p_out` and `p_out_ref`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Generalized Transposes\n",
    "\n",
    "In this example, it is shown how diezDecomp can handle arbitrary transpose operations with complex conditions, such as:\n",
    "* Mismatched intersections between the 2D pencil decompositions.\n",
    "* Custom array padding for each MPI task.\n",
    "* Array order (e.g., `x-y-z` or `y-z-x`) that is different for the input/output arrays.\n",
    "* Random transpose directions (e.g. $x \\to y$, $z \\to x$, etc.)\n",
    "\n",
    "To simplify the process, the python script `gen_random_transposes.py` generates random configurations, which are read by Fortran (as an input file) and are applied. The results are verified as before, by pre-computing the expected values for `p_in` and `p_out_ref`.\n",
    "\n",
    "This example can be considered as a baseline to use diezDecomp transposes in non-trivial settings.\n",
    "\n",
    "Notes about the input:\n",
    "* `order_in` is the local order (e.g. `y-z-x`) for the data in the input array `p_in`.\n",
    "    * Similarly, `order_out` is the local order for the output array `p_out`.\n",
    "    * `order_intermediate` is the local order used for packing/unpacking inside diezDecomp.\n",
    "        * The final results never depend on `order_intermediate`, but some settings offer higher performance.\n",
    "* `flat_mpi_ranks_in` is an array that specifies the location of each MPI task in the global grid layout (for the input array `p_in`):\n",
    "    * For example, `flat_mpi_ranks_in(2,:) = [3,4,5]` means the `MPI_task=2` uses the position `[3,4,5]` in the grid layout for the pencil distribution: ($p_x \\times p_y \\times p_z$).\n",
    "    * The values of `flat_mpi_ranks_in` are always given in the global $x/y/z$ coordinates. The local orders (`order_in/order_out`) are not considered, since this is a global descriptor.\n",
    "    * `flat_mpi_ranks_out` follows the same logic (as `flat_mpi_ranks_in`), but it specifies the location of each MPI task for the output array `p_out`.\n",
    "    * Please note that diezDecomp can handle any arbitrary values for `flat_mpi_ranks_*` (even randomized).\n",
    "* `offset6_in` is the padding for the input array `p_in` in each dimension:\n",
    "    * `offset6_in(i,:,0)` is the padding at the beggining of the dimension `i`, whereas `offset6_in(i,:,1)` is the padding added at the end of such dimension.\n",
    "    * `offset6_out` follows the same conventions, but for the output array `p_out`.\n",
    "    * Please note that both `offset6_in` and `offset6_out` follow the orders given by `order_in` and `order_out` respectively.\n",
    "* `n3_in` is the local array size for `p_in`, but following the local order given by `order_in`.\n",
    "    * In this example, `n3_in` is the inner array size excluding `offset6_in`, so both quantities are added inside the Fortran code (when needed).\n",
    "         * However, please note that the array shapes passed to diezDecomp (`sp_in` and `sp_out`) include the padding arrays (`offset6_in` and `offset6_out`).\n",
    "    * Similarly, `n3_out` specifies the grid size for `p_out` (excluding `offset6_out`).\n",
    "\n",
    "### API Summary (Example 2)\n",
    "\n",
    "In this example, it is shown how diezDecomp can be applied to nontrivial settings, by calling only 4 commands:\n",
    "\n",
    "```\n",
    "! recover grid layout for MPI tasks, starting from lo_in/out\n",
    "call diezdecomp_track_mpi_decomp(lo_in , obj_rank_in , irank, nproc, order_in)\n",
    "call diezdecomp_track_mpi_decomp(lo_out, obj_rank_out, irank, nproc, order_out)\n",
    "\n",
    "! initialize the transpose descriptor (tr)\n",
    "call diezdecomp_generic_fill_tr_obj(tr, obj_rank_in, obj_rank_out, sp_in, offset6_in, sp_out, offset6_out, order_in, order_out, order_intermediate, allow_alltoallv, i_a2av, j_a2av, wsize, allow_autotune_reorder)\n",
    "\n",
    "! call diezDecomp (only this command is needed inside DNS/LES iterations)\n",
    "call diezdecomp_transp_execute_generic_buf(tr, p_in, p_out, work)\n",
    "```\n",
    "\n",
    "The inputs for the code are once again summarized below:\n",
    "\n",
    "* `lo_in`\n",
    "* `lo_out`\n",
    "* `irank` (global rank of MPI task)\n",
    "* `nproc` (global number of MPI processes)\n",
    "* `order_in` (explained above)\n",
    "* `order_out`\n",
    "* `order_intermediate`\n",
    "* `sp_in`  (3D shape of `p_in`, including padding)\n",
    "* `sp_out` (3D shape of `p_out`, including padding)\n",
    "* `offset6_in`\n",
    "* `offset6_out`\n",
    "* `allow_autotune_reorder` (autotuning option, can be set to false) (please see notes below about autotuning)\n",
    "* `allow_alltoallv`        (classic MPI alternative, can be set to false)\n",
    "* `i_a2av`                 (only read if allow_alltoallv is active)\n",
    "* `j_a2av`                 (only read if allow_alltoallv is active)\n",
    "\n",
    "* Note:\n",
    "    * `wsize` is a secondary output, with the size of the work buffer for `diezdecomp_transp_execute_generic_buf`.\n",
    "\n",
    "In Example 3, it will be shown that diezDecomp includes a transpose mode which does not require an independent memory buffer (`work`), but it is subject to significant restrictions that the user is responsible for checking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 (Advanced): Generalized Transposes without Work Buffer\n",
    "### (Optional Example, Subject to Strong Restrictions)\n",
    "\n",
    "In the previous example (2), diezDecomp is called using a `work` array buffer, with enough space to store both the input and output arrays (`total_size(p_in)+total_size(p_out)`).\n",
    "\n",
    "This is necessary to ensure that:\n",
    "* There is always enough space to store auxiliary variables.\n",
    "* All data in the arrays `p_in` and `p_out` is fully preserved, and the padded cells positions `offset6_in/out` are never modified:\n",
    "    * The data in `p_in` is initially copied to the auxiliary memory buffer (`work`).\n",
    "    * Only the final results are written to `p_out` (always excluding the padded cell positions).\n",
    "\n",
    "While the previous behavior is ideal, a large memory buffer is needed (`work`). For applications that require memory optimization, diezDecomp offers a memory-lean alternative, which is given by the suroutine: `diezdecomp_transp_execute_generic_nobuf`. This subroutine does not require a memory buffer (`work`), yet it is subject to strong restrictions:\n",
    "* `p_in` might be overwriten (in-place operations).\n",
    "* The padded cells covered by `offset6_in/out` might be overwritten (and thus contain left-over data).\n",
    "* `p_in` and `p_out` must be pointers to memory buffers, with minimum size: `min_size=max(total_size(p_in),total_size(p_out))`.\n",
    "    * If either `p_in` or `p_out` is shorter than `min_size`, then the respective pointer must start at the beggining of the memory buffer: `p_in/out(0:?,0:?,0:?) -> p_in/out_buf(0:?)`. In this way, Fortran can store extra information at the end of the buffer using the assummed-size arrays (e.g., `p_in(0:*)` or `p_out(0:*)`).\n",
    "\n",
    "While the previous conditions sound restrictive, DNS/LES solvers typically use transpose operations inside Poisson solvers or parallel tridiagonal solvers (PCR-DTDMA). In both of these subroutines, the previous conditions can be accepted:\n",
    "* The input array `p_in` contains temporary values obtained from FFT operations or cyclic reduction, which are discarded afterwards.\n",
    "    * This implies that overwriting `p_in` using in-place operations is acceptable.\n",
    "* The information in the padded cells of `p_in/out` is outdated after all the operations performed by Poisson solvers or PCR-DTDMA algorithms. \n",
    "    * Therefore, overwriting such padded cells (`offset6_in/out`) is not an issue.\n",
    "    * If halo cells are necessary, the halo exchange functions must be called again.\n",
    "        * Some DNS codes do not require halo cells, but rather use padded cells as auxiliary storage to meet the requirements of libraries, such as `cuDecomp`, `rocFFT`, etc.\n",
    "            * In these scenarios, the values of the padded cells can always be overwritten after the FFT operations are completed.\n",
    "* As it is shown in the Fortran example, only a few lines of code are required to modify the declaration of `p_in` or `p_out`, such that they are pointers towards (existing) memory buffers.\n",
    "\n",
    "Based on the previous discussion, `diezdecomp_transp_execute_generic_nobuf` is a valid alternative for many DNS solvers requiring memory optimization. However, the user is responsible for ensuring that the previous conditions are acceptable nonetheless.\n",
    "\n",
    "The Fortran code in Example 3 showcases how `diezdecomp_transp_execute_generic_nobuf` can be used to perform the same generic transposes shown in Example 2, obtaining identical results for the (non-padded) cells in `p_out`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autotuning for Transpose Operations\n",
    "\n",
    "diezDecomp features multiple autotuning choices for transpose operations:\n",
    "* Synchronous vs Asynchronous MPI operations\n",
    "* Batched vs Simultaneous Data Packing/Unpacking\n",
    "* For-loop Order for GPU Kernels in Packing/Unpacking Operations\n",
    "* Intermediate MPI buffer Indexing Order\n",
    "\n",
    "Each of these options is explained below.\n",
    "\n",
    "### Synchronous vs Asynchronous MPI operations\n",
    "\n",
    "By default, diezDecomp works with asynchronous MPI operations (`MPI_ISend/IRecv`). However, it is also possible to enable (synchronous) `MPI_Alltoallv` transpose operations.\n",
    "\n",
    "This is accomplished with:\n",
    "* Generic API: Activate the flag `allow_alltoallv` in the subroutine `diezdecomp_generic_fill_tr_obj`.\n",
    "* CaNS API: Enable the global flag `diezdecomp_enable_alltoallv` (CaNS API).\n",
    "\n",
    "If `MPI_Alltoallv` operations are allowed, diezDecomp will first perform strict checks to determine if the option is compatible with the input/output grid layout for the MPI tasks: ($p_x \\times p_y \\times p_z$). The compatibility checks involve multiple factors, such as analyzing the (local) order of the MPI tasks in every row/column, and whether information must be transfered in the Cartesian direction orthogonal to the transpose operation. If the `MPI_Alltoallv` operation is rejected by the compatibility checks, diezDecomp will forcefully disable this option (`use_alltoallv=.false.`), and asynchronous MPI operations (`MPI_ISend/IRecv`) will be used instead.\n",
    "\n",
    "When `MPI_Alltoallv` transfers are permitted (after the compatibility checks), diezDecomp will perform a quick benchmark to check if this is faster than asynchronous MPI transfers (`MPI_ISend/IRecv`).\n",
    "\n",
    "If the user wishes to force diezDecomp to use `MPI_Alltoallv` operations (regardless of the autotuning results or compatibility checks), the following code can be used:\n",
    "\n",
    "```\n",
    "! initialize the transpose descriptor (tr)\n",
    "call diezdecomp_generic_fill_tr_obj(tr, obj_rank_in, obj_rank_out, sp_in, offset6_in, sp_out, offset6_out, order_in, order_out, order_intermediate, allow_alltoallv, i_a2av, j_a2av, wsize, allow_autotune_reorder)\n",
    "\n",
    "! ----- force diezDecomp to use mpi_alltoallv -----\n",
    "tr%use_alltoallv  = .true.  ! enable mpi_alltoallv (warning: this overwrites the compatibility checks)\n",
    "tr%use_isendirecv = .false. ! disable asynchronous operations (mpi_isend/irecv)\n",
    "tr%chosen_backend = .true.  ! avoid autotuning\n",
    "```\n",
    "The meaning of the last three variables is summarized below:\n",
    "* `tr%use_isendirecv`:\n",
    "    * This option enables `MPI_ISend/IRecv` transfers for diezDecomp transposes. Due to the robustness of this approach, all initialization methods for diezDecomp transposes enable this option (by default).\n",
    "* `tr%use_alltoallv`:\n",
    "    * Boolean flag to enable `mpi_alltoallv` transposes in diezDecomp. As discussed before, all diezDecomp initialization methods will perform compatibility checks to determine if this option is feasible. If issues are found, `use_alltoallv=.false.` will be forced, even if the flags  `allow_alltoallv` (generic API) or `diezdecomp_enable_alltoallv` (CaNS API) were activated in the initialization routine.\n",
    "\n",
    "* `tr%chosen_backend`:\n",
    "    * This variable is used by diezDecomp to check whether a communication backend has already been chosen (`MPI_ISend/IRecv` vs. `MPI_Alltoallv`).\n",
    "         * If both  `use_alltoallv` and `use_isendirecv` are active, diezDecomp will perform an autotuning benchmark, and the slowest option will be disabled.\n",
    "         * Otherwise, if only one MPI option is active (`use_alltoallv` or `use_isendirecv`), diezDecomp will continue using the chosen option.\n",
    "             * Due to this edge-case behavior, manually changing `chosen_backend` is not strictly necessary.\n",
    "    * Please note that if the user adds new communication backends to diezDecomp (e.g. NCCL or RCCL), it  necessary to disable them too when `chosen_backend` is set to `.false.`. \n",
    "\n",
    "### Batched vs Simultaneous Data Packing/Unpacking\n",
    "\n",
    "In transpose operations, the main performance bottleneck are typically MPI data transfers. However, other operations can also create significant performance overheads. For instance, MPI subroutines use 1D data buffers; containing all information sent or received by the operation. Therefore, data must be packed into these 1D buffers before sending, and received data must be unpacked afterwards.\n",
    "\n",
    "For small-scale simulations, one of the most efficient approaches is to launch one GPU kernel to pack or unpack data for every GPU device used as target/destination in the (local) MPI operation. This is called a \"batched\" mode, since data is processed in small portions.\n",
    "\n",
    "However, for extreme-scale simulations, batched operations are inefficient, since thousands of GPU kernels can be launched together. To avoid this issue, diezDecomp includes a \"simultaneous\" data packing/unpacking mode, where only one GPU kernel is launched to handle the entire 1D memory buffer of the MPI transfer. The \"simultaneous\" operation method is susbtantially more efficient for extreme-scale simulations, and it can also deliver high performance for small-scale simulations.\n",
    "\n",
    "By default, diezDecomp performs auto-tuning to determine if the \"batched\" or \"simultaneous\" mode is more efficient. Packing and unpacking operations are autotuned separately. Usually, \"batched\" operations are faster for small-scale simulations, whereas \"simultaneous\" data packing/unpacking is better for extreme-scale simulations. The main reason that the \"simultaneous\" mode is (slightly) slower for small DNS/LES runs is because it uses an advanced GPU kernel containing more variables, which are simplified in \"batched\" runs (at the expense of launching multiple kernels).\n",
    "\n",
    "To disable auto-tuning, the user can manually specify the mode for data packing/unpacking with the following variables:\n",
    "* `tr%send_autotuned`:\n",
    "    * Mode for data packing before MPI transfers. (`1`: simultaneous, `2`: batched)\n",
    "* `tr%recv_autotuned`:\n",
    "    * Mode for data unpacking after MPI transfers. (`1`: simultaneous, `2`: batched)\n",
    "\n",
    "### For-loop Order for GPU Kernels in Packing/Unpacking Operations\n",
    "\n",
    "Beyond choosing between \"batched\" or \"simultaneous\" modes (for data packing/unpacking), another important factor is the for-loop order of the GPU kernels. While it may sound redundant, for transposes having different input/output array orders (e.g. $y/z/x \\to x/z/y$), choosing the fastest for-loop order for the GPU kernels is not trivial (e.g. $k \\to j \\to i$ or $k \\to i \\to j$). The running times of GPU kernels can change by an order of magnitude, depending on the for-loop order.\n",
    "\n",
    "To avoid performance issues, diezDecomp performs an autotuning benchmark to identify the optimal for-loop order for its GPU kernels. Each mode (batched vs. simultaneous) and task (packing vs. unpacking) is benchmarked separately to identify the best for-loop order <sup>1</sup>.\n",
    "\n",
    "Based on experience, the for-loop orders of the GPU kernels in diezDecomp can be chosen by the user using the following variables:\n",
    "* `tr%send_mode_op_batched`:\n",
    "    * For-loop order for the \"batched\" mode, in data packing operations (before MPI transfers).\n",
    "* `tr%send_mode_op_simul`:\n",
    "    * For-loop order for the \"simultaneous\" mode, in data packing operations (before MPI transfers).\n",
    "* `tr%recv_mode_op_batched`:\n",
    "    * For-loop order for the \"batched\" mode, in data unpacking operations (after MPI transfers).\n",
    "* `tr%recv_mode_op_simul`:\n",
    "    * For-loop order for the \"simultaneous\" mode, in data unpacking operations (after MPI transfers).\n",
    "\n",
    "The previously listed variables correspond to integers, with values between [1-6]:\n",
    "* 1: $i \\to j \\to k$\n",
    "    * The input array always has a (local) index order: $A(i,j,k)$. Only the for-loop order changes.\n",
    "    * Please note that MPI 1D data buffers can use another indexing order (e.g. $(j,i,k)$), which is controlled by the variable `order_intermediate` mentioned in Example 2.\n",
    "* 2: $i \\to k \\to j$\n",
    "* 3: $j \\to i \\to k$\n",
    "* 4: $j \\to k \\to i$\n",
    "* 5: $k \\to i \\to j$\n",
    "* 6: $k \\to j \\to i$\n",
    "\n",
    "In Fortran GPU kernels, for 3D arrays with $A(i,j,k)$ indexing, the for-loop order $k \\to j \\to i$ (number 6) is usually among the fastest, whereas the modes (1-2) are the slowest ($i \\to j \\to k$ and $i \\to k \\to j$). The first two modes (1-2) are slower, because $i$ is the innermost dimension in Fortran, and thus the for-loop order should be reversed. Due to this reason, diezDecomp disables the modes (1-2) during autotuning benchmarks, but the user can enable them if desired.\n",
    "\n",
    "<sup>1</sup>: Technically, each GPU kernel in the \"batched\" packing/unpacking mode can be benchmarked separately for its optimal for-loop order. This is relatively simple to accomplish in diezDecomp, but it has been disabled for now. The main technical challenge is that the precision of `MPI_WTIME` is often coarser than the measured running times. Moreover, the relevance of further autotuning is questionable. With the current strategy, the data packing/unpacking operations are typically orders of magnitude faster than MPI operations.\n",
    "\n",
    "\n",
    "### Intermediate MPI buffer Indexing Order\n",
    "\n",
    "As previously mentioned, the indexing order of the MPI data buffers can also affect the performance of diezDecomp. Due to this reason, users are allowed to perform an auto-tuning benchmark for the best indexing order of the MPI data buffers.\n",
    "\n",
    "This option corresponds to a nested for-loop, which will perform all the previous (autotuning) benchmarks for each configuration (`order_intermediate`):\n",
    "\n",
    "* $i \\to j \\to k$\n",
    "* $i \\to k \\to j$\n",
    "* $j \\to i \\to k$\n",
    "* $j \\to k \\to i$\n",
    "* $k \\to i \\to j$\n",
    "* $k \\to j \\to i$\n",
    "\n",
    "As a general rule, this benchmark can be avoided for input/output transpose arrays with simple indexing orders. For instance, if both the input and output arrays have the same index order (e.g. $(j,i,k)$), using the same format for the MPI 1D buffers is likely a good choice.\n",
    "\n",
    "In the generic API (`diezdecomp_generic_fill_tr_obj`), the autotuning of the indexing order for the MPI buffers can be activated with the boolean flag: `allow_autotune_reorder`. Similarly, in the CaNS API, the (boolean) global variable `diezdecomp_allow_autotune_reorder` controls whether this type of autotuning is performed.\n",
    "\n",
    "If autotuning is disabled, the variable `order_intermediate` mentioned in Example 2 will determine the indexing order for the MPI data buffers. Please note that both MPI send and receive 1D data buffers have the same indexing system.\n",
    "\n",
    "### Autotuning Report (Transposes)\n",
    "\n",
    "So far, this section has presented the autotuning options for diezDecomp transposes. To understand better the impact of different choices, diezDecomp includes the subroutine `diezdecomp_summary_transp_autotuning`, which prints a summary of all autotuned parameters in the code. The transpose object `tr` has internal variables that record the benchmarked times for every tested option. Therefore, no additional benchmarks are performed when `diezdecomp_summary_transp_autotuning` is called.\n",
    "\n",
    "Additionally, please note that for DNS/LES solvers, there likely exist fixed autotuning parameter choices that deliver high performance in most practical settings:\n",
    "* Synchronous vs asynchronous MPI transfers.\n",
    "* Batched vs. simultaneous data packing/unpacking modes.\n",
    "* Indexing order for MPI data buffers (`order_intermediate`).\n",
    "* For-loop orders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Information\n",
    "\n",
    "After analyzing the previous examples, further details about diezDecomp transposes can be found in the specialized test suite: `./tests/transpose`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
